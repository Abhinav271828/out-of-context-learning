import torch
from torch.utils.data import Dataset
import random
from tqdm import tqdm

class MembershipFewShot(Dataset):
    """
    Create a dataset for the membership task in a few-shot setting.
    Parameters:
        num_examples (int): the number of examples per task.
        dataset_size (int): the number of tasks in the dataset.
        neg_samples (float): the fraction of negative samples per task. a number between 0 and 1.
    
    The dataset is generated by sampling a language L_i at random and generating num_examples examples from it.
    On average, neg_samples * num_examples negative examples are generated (randomly) and the rest are positive examples.
    Note that the probability of generating a positive sample by chance is negligible.
    Negative samples are marked as -1 and positive samples are marked as 1.
    This label is the last element of the input tensor.

    The test samples are generated with a 50% chance of being negative.
    Negative samples are generated by sampling a random length and filling it with random symbols from the alphabet, as
    well as a final 0, which is a placeholder for the classification label.
    Positive samples are sampled from the language L_i and similarly labelled as 0.

    The ground-truth labels are in a separate tensor.

    We also store the language L_i that was used to generate the task.
    """
    def __init__(self, num_examples, dataset_size, neg_samples=0.5):
        self.num_examples = num_examples
        self.dataset_size = dataset_size
        self.neg_samples = neg_samples

        self.data = torch.zeros(self.dataset_size, self.num_examples+1, 21)
        self.labels = torch.zeros(self.dataset_size)
        self.languages = torch.zeros(self.dataset_size)
        self.alphabet = {'a': 0, 'b': 1, 'c': 2}
        self.generate_data()
    
    def generate_data(self):
        for i in tqdm(range(self.dataset_size), desc='Generating data'):
            language = random.randint(1, 6)
            self.languages[i] = language
            with open(f'data/L{language}.txt', 'r') as f:
                # Inputs (examples)
                samples = f.readlines()
                for j in range(self.num_examples):
                    # Negative samples
                    if random.random() < self.neg_samples:
                        length = random.randint(1, 20)
                        self.data[i][j] = torch.tensor(random.choices(sorted(self.alphabet.values()), k=length) + [0] * (20-length) + [-1])
                    # Positive samples
                    else:
                        sample = random.choice(samples).strip()
                        rep = [alphabet[c] for c in sample] + [0] * (20-len(sample)) + [1]
                        if (len(rep) > 21): print(sample, rep)
                        self.data[i][j] = torch.tensor([self.alphabet[c] for c in sample] + [0] * (20-len(sample)) + [1])
                
                # Test sample
                # Negative
                if random.random() < 0.5:
                    length = random.randint(1, 20)
                    self.data[i][self.num_examples] = torch.tensor(random.choices(sorted(self.alphabet.values()), k=length) + [0] * (20-length) + [0])
                    self.labels[i] = 0
                # Positive
                else:
                    sample = random.choice(samples).strip()
                    self.data[i][self.num_examples] = torch.tensor([self.alphabet[c] for c in sample] + [0] * (20-len(sample)) + [0])
                    self.labels[i] = 1

    def __len__(self):
        return self.dataset_size

    def __getitem__(self, idx):
        """
        Returns a pair ([num_examples+1, 21], [1])
        where
        - num_examples+1 is the number of examples in the task, including the test sample.
        - 21 is the length of the input vector, including the label.
        - 1 is the label of the test sample (whose label element is 0).
        """
        return self.data[idx], self.labels[idx]